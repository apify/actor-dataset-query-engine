import logging
from typing import Any

from llama_index.core.agent import ReActAgent
from llama_index.core.chat_engine.types import AgentChatResponse
from llama_index.core.tools import FunctionTool
from llama_index.llms.openai import OpenAI

from .tools import LLMRegistry, execute_sql, is_query_sql, synthesize_results, user_query_to_sql

determine_query_tool = FunctionTool.from_defaults(fn=is_query_sql)
user_query_to_sql_tool = FunctionTool.from_defaults(fn=user_query_to_sql)
execute_sql_tool = FunctionTool.from_defaults(fn=execute_sql)
results_synthesize_tool = FunctionTool.from_defaults(fn=synthesize_results)


logger = logging.getLogger('apify')


async def run_agent(
        query: str, table_name: str, table_schema: dict[str, Any], llm: OpenAI, verbose: bool = False
) -> AgentChatResponse:
    """
    Runs an agent to process a query using an LLM and tools.

    The function initializes a ReAct agent with specific tools to process a user-provided query.
    It sets the provided LLM, loads the schema for the dataset identified by the table name,
    constructs a context for the agent, and processes the query through the agent. The response
    generated by the agent is logged and returned as output.

    Args:
        query: Query string provided by the user for processing.
        table_name: The name of the table whose schema is to be used for the query.
        table_schema: Schema of the database table.
        llm: The language model to be used for processing.
        verbose: Flag to enable verbose logging.

    Returns:
        A string containing the response from the agent.
    """
    LLMRegistry.set(llm)

    context = f'Table name provided by user: {table_name}. Table schema: {table_schema}'

    # Initialize the ReAct Agent with the Tools (LLM not pre-instantiated)
    agent = ReActAgent.from_tools(
        [
            determine_query_tool,
            user_query_to_sql_tool,
            execute_sql_tool,
            results_synthesize_tool,
        ],
        llm=llm,
        verbose=verbose,
        allow_parallel_tool_calls=False,
        context=context,
    )

    response: AgentChatResponse = await agent.achat(query)
    logger.info(f'Agent answer: {response.response}')
    return response
